"""
ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å›å¸°ãƒ¢ãƒ‡ãƒ«

Transformerã¨GNNã‚’çµ„ã¿åˆã‚ã›ãŸã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã€‚
ä¸ç¢ºå®Ÿæ€§æ¨å®šæ©Ÿèƒ½ä»˜ãã§ã€13å€‹ã®CNSã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®pIC50ã‚’äºˆæ¸¬ã€‚
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
from typing import Dict, List, Tuple, Optional, Union, Any
import math

from .transformer_model import TransformerRegressor
from .gnn_model import GNNRegressor


class EnsembleRegressor(nn.Module):
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å›å¸°ãƒ¢ãƒ‡ãƒ«"""
    
    def __init__(
        self,
        transformer_model: Optional[TransformerRegressor] = None,
        gnn_model: Optional[GNNRegressor] = None,
        weights: List[float] = [0.6, 0.4],
        num_targets: int = 13,
        use_uncertainty: bool = True,
        uncertainty_threshold: float = 0.3
    ):
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        
        Args:
            transformer_model: Transformerãƒ¢ãƒ‡ãƒ«
            gnn_model: GNNãƒ¢ãƒ‡ãƒ«
            weights: ãƒ¢ãƒ‡ãƒ«é‡ã¿ [transformer_weight, gnn_weight]
            num_targets: äºˆæ¸¬ã‚¿ãƒ¼ã‚²ãƒƒãƒˆæ•°
            use_uncertainty: ä¸ç¢ºå®Ÿæ€§æ¨å®šã‚’ä½¿ç”¨ã™ã‚‹ã‹
            uncertainty_threshold: ä¸ç¢ºå®Ÿæ€§é–¾å€¤
        """
        super().__init__()
        
        self.transformer_model = transformer_model
        self.gnn_model = gnn_model
        self.weights = weights
        self.num_targets = num_targets
        self.use_uncertainty = use_uncertainty
        self.uncertainty_threshold = uncertainty_threshold
        
        # é‡ã¿ã‚’æ­£è¦åŒ–
        self.weights = torch.tensor(weights, dtype=torch.float32)
        self.weights = F.softmax(self.weights, dim=0)
        
        # ä¸ç¢ºå®Ÿæ€§æ¨å®šç”¨ã®é‡ã¿
        if use_uncertainty:
            self.uncertainty_weights = nn.Parameter(torch.ones(num_targets))
        
        # ãƒ¢ãƒ‡ãƒ«ãŒæä¾›ã•ã‚Œãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½œæˆ
        if transformer_model is None:
            self.transformer_model = TransformerRegressor(
                input_dim=2279,
                hidden_dim=512,
                num_layers=4,
                num_heads=8,
                num_targets=num_targets
            )
        
        if gnn_model is None:
            self.gnn_model = GNNRegressor(
                node_features=78,
                edge_features=12,
                hidden_dim=256,
                num_layers=3,
                num_targets=num_targets,
                use_attention=True,
                use_scaffold_features=True
            )
    
    def forward(
        self,
        x: torch.Tensor,
        node_features: Optional[torch.Tensor] = None,
        edge_features: Optional[torch.Tensor] = None,
        adj_matrix: Optional[torch.Tensor] = None,
        scaffold_features: Optional[torch.Tensor] = None
    ) -> torch.Tensor:
        """
        é †ä¼æ’­
        
        Args:
            x: çµ±åˆç‰¹å¾´é‡ (batch_size, input_dim)
            node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ (batch_size, num_nodes, node_features)
            edge_features: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡ (batch_size, num_nodes, num_nodes, edge_features)
            adj_matrix: éš£æ¥è¡Œåˆ— (batch_size, num_nodes, num_nodes)
            scaffold_features: éª¨æ ¼ç‰¹å¾´é‡ (batch_size, scaffold_dim)
            
        Returns:
            äºˆæ¸¬å€¤ (batch_size, num_targets)
        """
        predictions = []
        
        # Transformeräºˆæ¸¬
        if self.transformer_model is not None:
            transformer_pred = self.transformer_model(x)
            predictions.append(transformer_pred)
        
        # GNNäºˆæ¸¬
        if self.gnn_model is not None and node_features is not None:
            gnn_pred = self.gnn_model(node_features, edge_features, adj_matrix, scaffold_features)
            predictions.append(gnn_pred)
        
        # äºˆæ¸¬ã‚’çµåˆ
        if len(predictions) == 0:
            raise ValueError("No models available for prediction")
        
        # é‡ã¿ä»˜ãå¹³å‡
        ensemble_pred = torch.zeros_like(predictions[0])
        for i, pred in enumerate(predictions):
            ensemble_pred += self.weights[i] * pred
        
        return ensemble_pred
    
    def predict_with_uncertainty(
        self,
        x: torch.Tensor,
        node_features: Optional[torch.Tensor] = None,
        edge_features: Optional[torch.Tensor] = None,
        adj_matrix: Optional[torch.Tensor] = None,
        scaffold_features: Optional[torch.Tensor] = None,
        num_samples: int = 100
    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸäºˆæ¸¬
        
        Args:
            x: çµ±åˆç‰¹å¾´é‡
            node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
            edge_features: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡
            adj_matrix: éš£æ¥è¡Œåˆ—
            scaffold_features: éª¨æ ¼ç‰¹å¾´é‡
            num_samples: ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å›æ•°
            
        Returns:
            äºˆæ¸¬å€¤ã€ä¸ç¢ºå®Ÿæ€§ã€ä¿¡é ¼åº¦
        """
        if not self.use_uncertainty:
            pred = self.forward(x, node_features, edge_features, adj_matrix, scaffold_features)
            return pred, torch.zeros_like(pred), torch.ones_like(pred)
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®ä¸ç¢ºå®Ÿæ€§ã‚’è¨ˆç®—
        transformer_uncertainty = None
        gnn_uncertainty = None
        
        if self.transformer_model is not None:
            transformer_mean, transformer_std = self.transformer_model.predict_with_uncertainty(
                x, num_samples=num_samples
            )
            transformer_uncertainty = transformer_std
        
        if self.gnn_model is not None and node_features is not None:
            gnn_mean, gnn_std = self.gnn_model.predict_with_uncertainty(
                node_features, edge_features, adj_matrix, scaffold_features, num_samples
            )
            gnn_uncertainty = gnn_std
        
        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble_pred = self.forward(x, node_features, edge_features, adj_matrix, scaffold_features)
        
        # ä¸ç¢ºå®Ÿæ€§ã‚’çµ±åˆ
        if transformer_uncertainty is not None and gnn_uncertainty is not None:
            # ä¸¡æ–¹ã®ãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨å¯èƒ½
            uncertainty = self.weights[0] * transformer_uncertainty + self.weights[1] * gnn_uncertainty
        elif transformer_uncertainty is not None:
            # Transformerã®ã¿
            uncertainty = transformer_uncertainty
        elif gnn_uncertainty is not None:
            # GNNã®ã¿
            uncertainty = gnn_uncertainty
        else:
            # ä¸ç¢ºå®Ÿæ€§ãŒè¨ˆç®—ã§ããªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
            uncertainty = torch.ones_like(ensemble_pred) * 0.5
        
        # ä¿¡é ¼åº¦ã‚’è¨ˆç®—
        confidence = torch.exp(-uncertainty * self.uncertainty_weights)
        confidence = torch.clamp(confidence, 0.0, 1.0)
        
        return ensemble_pred, uncertainty, confidence
    
    def get_model_contributions(
        self,
        x: torch.Tensor,
        node_features: Optional[torch.Tensor] = None,
        edge_features: Optional[torch.Tensor] = None,
        adj_matrix: Optional[torch.Tensor] = None,
        scaffold_features: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        å„ãƒ¢ãƒ‡ãƒ«ã®å¯„ä¸åº¦ã‚’å–å¾—
        
        Args:
            x: çµ±åˆç‰¹å¾´é‡
            node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
            edge_features: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡
            adj_matrix: éš£æ¥è¡Œåˆ—
            scaffold_features: éª¨æ ¼ç‰¹å¾´é‡
            
        Returns:
            å„ãƒ¢ãƒ‡ãƒ«ã®å¯„ä¸åº¦
        """
        contributions = {}
        
        # Transformerå¯„ä¸åº¦
        if self.transformer_model is not None:
            transformer_pred = self.transformer_model(x)
            contributions['transformer'] = transformer_pred
        
        # GNNå¯„ä¸åº¦
        if self.gnn_model is not None and node_features is not None:
            gnn_pred = self.gnn_model(node_features, edge_features, adj_matrix, scaffold_features)
            contributions['gnn'] = gnn_pred
        
        return contributions
    
    def get_feature_importance(
        self,
        x: torch.Tensor,
        node_features: Optional[torch.Tensor] = None,
        edge_features: Optional[torch.Tensor] = None,
        adj_matrix: Optional[torch.Tensor] = None,
        scaffold_features: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
        
        Args:
            x: çµ±åˆç‰¹å¾´é‡
            node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
            edge_features: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡
            adj_matrix: éš£æ¥è¡Œåˆ—
            scaffold_features: éª¨æ ¼ç‰¹å¾´é‡
            
        Returns:
            å„ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦
        """
        importance = {}
        
        # Transformerç‰¹å¾´é‡é‡è¦åº¦
        if self.transformer_model is not None:
            transformer_importance = self.transformer_model.get_feature_importance(x)
            importance['transformer'] = transformer_importance
        
        # GNNç‰¹å¾´é‡é‡è¦åº¦ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if self.gnn_model is not None and node_features is not None:
            # ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡ã®é‡è¦åº¦ã‚’è¨ˆç®—
            node_importance = torch.abs(node_features).mean(dim=1).mean(dim=0)
            importance['gnn'] = node_importance
        
        return importance
    
    def get_embeddings(
        self,
        x: torch.Tensor,
        node_features: Optional[torch.Tensor] = None,
        edge_features: Optional[torch.Tensor] = None,
        adj_matrix: Optional[torch.Tensor] = None,
        scaffold_features: Optional[torch.Tensor] = None
    ) -> Dict[str, torch.Tensor]:
        """
        åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã‚’å–å¾—
        
        Args:
            x: çµ±åˆç‰¹å¾´é‡
            node_features: ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡
            edge_features: ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡
            adj_matrix: éš£æ¥è¡Œåˆ—
            scaffold_features: éª¨æ ¼ç‰¹å¾´é‡
            
        Returns:
            å„ãƒ¢ãƒ‡ãƒ«ã®åŸ‹ã‚è¾¼ã¿è¡¨ç¾
        """
        embeddings = {}
        
        # TransformeråŸ‹ã‚è¾¼ã¿
        if self.transformer_model is not None:
            transformer_emb = self.transformer_model.get_embeddings(x)
            embeddings['transformer'] = transformer_emb
        
        # GNNåŸ‹ã‚è¾¼ã¿
        if self.gnn_model is not None and node_features is not None:
            gnn_emb = self.gnn_model.get_graph_embeddings(
                node_features, edge_features, adj_matrix, scaffold_features
            )
            embeddings['gnn'] = gnn_emb
        
        return embeddings
    
    def update_weights(self, new_weights: List[float]):
        """ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’æ›´æ–°"""
        self.weights = torch.tensor(new_weights, dtype=torch.float32)
        self.weights = F.softmax(self.weights, dim=0)
    
    def get_uncertainty_threshold(self) -> float:
        """ä¸ç¢ºå®Ÿæ€§é–¾å€¤ã‚’å–å¾—"""
        return self.uncertainty_threshold
    
    def set_uncertainty_threshold(self, threshold: float):
        """ä¸ç¢ºå®Ÿæ€§é–¾å€¤ã‚’è¨­å®š"""
        self.uncertainty_threshold = threshold
    
    def save_model(self, path: str):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜"""
        torch.save({
            'model_state_dict': self.state_dict(),
            'weights': self.weights.tolist(),
            'num_targets': self.num_targets,
            'use_uncertainty': self.use_uncertainty,
            'uncertainty_threshold': self.uncertainty_threshold,
            'transformer_model': self.transformer_model.state_dict() if self.transformer_model else None,
            'gnn_model': self.gnn_model.state_dict() if self.gnn_model else None
        }, path)
    
    @classmethod
    def load_model(cls, path: str, device: str = 'cpu'):
        """ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        checkpoint = torch.load(path, map_location=device)
        
        # ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
        model = cls(
            weights=checkpoint['weights'],
            num_targets=checkpoint['num_targets'],
            use_uncertainty=checkpoint['use_uncertainty'],
            uncertainty_threshold=checkpoint['uncertainty_threshold']
        )
        
        # çŠ¶æ…‹è¾æ›¸ã‚’èª­ã¿è¾¼ã¿
        model.load_state_dict(checkpoint['model_state_dict'])
        
        # ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã®çŠ¶æ…‹è¾æ›¸ã‚’èª­ã¿è¾¼ã¿
        if checkpoint['transformer_model'] is not None:
            model.transformer_model.load_state_dict(checkpoint['transformer_model'])
        
        if checkpoint['gnn_model'] is not None:
            model.gnn_model.load_state_dict(checkpoint['gnn_model'])
        
        model.to(device)
        
        return model


class UncertaintyEstimator(nn.Module):
    """ä¸ç¢ºå®Ÿæ€§æ¨å®šå™¨"""
    
    def __init__(self, input_dim: int, num_targets: int, hidden_dim: int = 256):
        super().__init__()
        self.input_dim = input_dim
        self.num_targets = num_targets
        self.hidden_dim = hidden_dim
        
        self.uncertainty_net = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(hidden_dim // 2, num_targets),
            nn.Softplus()  # æ­£ã®å€¤ã‚’ä¿è¨¼
        )
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """ä¸ç¢ºå®Ÿæ€§ã‚’æ¨å®š"""
        return self.uncertainty_net(x)


# ä¾¿åˆ©é–¢æ•°
def create_ensemble_model(
    transformer_model: Optional[TransformerRegressor] = None,
    gnn_model: Optional[GNNRegressor] = None,
    weights: List[float] = [0.6, 0.4],
    num_targets: int = 13,
    use_uncertainty: bool = True
) -> EnsembleRegressor:
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ"""
    return EnsembleRegressor(
        transformer_model=transformer_model,
        gnn_model=gnn_model,
        weights=weights,
        num_targets=num_targets,
        use_uncertainty=use_uncertainty
    )


def count_parameters(model: nn.Module) -> int:
    """ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°ã‚’è¨ˆç®—"""
    return sum(p.numel() for p in model.parameters() if p.requires_grad)


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    print("ğŸ§¬ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å›å¸°ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    # ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    transformer_model = TransformerRegressor(
        input_dim=2279,
        hidden_dim=512,
        num_layers=4,
        num_heads=8,
        num_targets=13
    )
    
    gnn_model = GNNRegressor(
        node_features=78,
        edge_features=12,
        hidden_dim=256,
        num_layers=3,
        num_targets=13,
        use_attention=True,
        use_scaffold_features=True
    )
    
    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆ
    ensemble_model = create_ensemble_model(
        transformer_model=transformer_model,
        gnn_model=gnn_model,
        weights=[0.6, 0.4],
        num_targets=13,
        use_uncertainty=True
    )
    
    print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {count_parameters(ensemble_model):,}")
    print(f"Transformerãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {count_parameters(transformer_model):,}")
    print(f"GNNãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•°: {count_parameters(gnn_model):,}")
    
    # ãƒ†ã‚¹ãƒˆç”¨å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
    batch_size = 32
    num_nodes = 50
    
    # çµ±åˆç‰¹å¾´é‡
    x = torch.randn(batch_size, 2279)
    
    # ã‚°ãƒ©ãƒ•ç‰¹å¾´é‡
    node_features = torch.randn(batch_size, num_nodes, 78)
    edge_features = torch.randn(batch_size, num_nodes, num_nodes, 12)
    adj_matrix = torch.randint(0, 2, (batch_size, num_nodes, num_nodes)).float()
    scaffold_features = torch.randn(batch_size, 20)
    
    print(f"çµ±åˆç‰¹å¾´é‡å½¢çŠ¶: {x.shape}")
    print(f"ãƒãƒ¼ãƒ‰ç‰¹å¾´é‡å½¢çŠ¶: {node_features.shape}")
    print(f"ã‚¨ãƒƒã‚¸ç‰¹å¾´é‡å½¢çŠ¶: {edge_features.shape}")
    print(f"éš£æ¥è¡Œåˆ—å½¢çŠ¶: {adj_matrix.shape}")
    print(f"éª¨æ ¼ç‰¹å¾´é‡å½¢çŠ¶: {scaffold_features.shape}")
    
    # é †ä¼æ’­
    ensemble_model.eval()
    with torch.no_grad():
        output = ensemble_model(x, node_features, edge_features, adj_matrix, scaffold_features)
        print(f"å‡ºåŠ›å½¢çŠ¶: {output.shape}")
        
        # å„ãƒ¢ãƒ‡ãƒ«ã®å¯„ä¸åº¦ã‚’å–å¾—
        contributions = ensemble_model.get_model_contributions(
            x, node_features, edge_features, adj_matrix, scaffold_features
        )
        print(f"å¯„ä¸åº¦: {list(contributions.keys())}")
        
        # ç‰¹å¾´é‡é‡è¦åº¦ã‚’å–å¾—
        importance = ensemble_model.get_feature_importance(
            x, node_features, edge_features, adj_matrix, scaffold_features
        )
        print(f"ç‰¹å¾´é‡é‡è¦åº¦: {list(importance.keys())}")
        
        # åŸ‹ã‚è¾¼ã¿è¡¨ç¾ã‚’å–å¾—
        embeddings = ensemble_model.get_embeddings(
            x, node_features, edge_features, adj_matrix, scaffold_features
        )
        print(f"åŸ‹ã‚è¾¼ã¿è¡¨ç¾: {list(embeddings.keys())}")
    
    # ä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸäºˆæ¸¬
    print("\nä¸ç¢ºå®Ÿæ€§ã‚’è€ƒæ…®ã—ãŸäºˆæ¸¬:")
    mean_pred, uncertainty, confidence = ensemble_model.predict_with_uncertainty(
        x, node_features, edge_features, adj_matrix, scaffold_features, num_samples=10
    )
    print(f"å¹³å‡äºˆæ¸¬å½¢çŠ¶: {mean_pred.shape}")
    print(f"ä¸ç¢ºå®Ÿæ€§å½¢çŠ¶: {uncertainty.shape}")
    print(f"ä¿¡é ¼åº¦å½¢çŠ¶: {confidence.shape}")
    
    # é‡ã¿ã‚’æ›´æ–°
    print("\né‡ã¿æ›´æ–°ãƒ†ã‚¹ãƒˆ:")
    ensemble_model.update_weights([0.7, 0.3])
    print(f"æ–°ã—ã„é‡ã¿: {ensemble_model.weights}")
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ
    print("\nãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ»èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ:")
    model_path = "test_ensemble_model.pth"
    ensemble_model.save_model(model_path)
    
    loaded_model = EnsembleRegressor.load_model(model_path)
    print(f"èª­ã¿è¾¼ã¿æˆåŠŸ: {type(loaded_model)}")
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    import os
    if os.path.exists(model_path):
        os.remove(model_path)
    
    print("\nâœ… ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å›å¸°ãƒ¢ãƒ‡ãƒ«ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
